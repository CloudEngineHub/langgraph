{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83bf198-9d20-447c-9565-123345dd90a9",
   "metadata": {},
   "source": [
    "# Add Long-term User Memory\n",
    "\n",
    "LangGraph already provides graph persistence as a first-class feature. That's all you need to have **thread** level memory (aka chat history memory).\n",
    "\n",
    "There are huge benefits to persisting memory **across threads**, however. This notebook shows how to implement a simple 'User Profile' type memory as an async process and connect it to your LangGraph.\n",
    "\n",
    "The user profile can be any schema. We will naively overwrite the user profile any time a new thread is scheduled to process memories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19614a-fb58-49d0-8fec-dcacc985fc75",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Let's install this project's prereqs. We will use Claude for everything. Feel free to swap it out for any model that can reasonably perform function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637a885-c557-43f1-8059-70d6d2ac7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install -U langgraph aiosqlite langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c16e7dc-66bf-4c78-af70-ae07aba93f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LANGCHAIN_PROJECT=langgraph-long-term-memory\n"
     ]
    }
   ],
   "source": [
    "%env LANGCHAIN_PROJECT=langgraph-long-term-memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44f855-d660-4ef3-a9d7-00fa4d42d2dd",
   "metadata": {},
   "source": [
    "## Memory DB\n",
    "\n",
    "First, we will set up a table in our database to store user memories. For this how-to, we will use `sqlite` (since it requires little additional setup), but you can swap this out with postgres or whatever other database you'd like.\n",
    "We will re-use this DB for our graph checkpointing.\n",
    "\n",
    "First, create the memories table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce108ac-9ee7-4712-a7bd-a3d1d7796ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiosqlite\n",
    "\n",
    "conn_string = \":memory:\"\n",
    "conn = aiosqlite.connect(conn_string)\n",
    "await conn\n",
    "async with conn.executescript(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS core_memories (\n",
    "        user_id TEXT NOT NULL,\n",
    "        memory TEXT NOT NULL,\n",
    "        PRIMARY KEY (user_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "):\n",
    "    await conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bb7ca-527d-41ce-a32a-6b97c49b26a7",
   "metadata": {},
   "source": [
    "Next, define the accessor methods. These just upsert or get the memory for a specific user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168dbcbd-545c-4579-bfa3-cea67e56879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def get_user_profile(conn, user_id):\n",
    "    async with conn.execute(\n",
    "        \"SELECT memory FROM core_memories WHERE user_id = ?\",\n",
    "        (user_id,),\n",
    "    ) as cursor:\n",
    "        if value := await cursor.fetchone():\n",
    "            memory_str = value[0]\n",
    "            return json.loads(memory_str)\n",
    "        return None\n",
    "\n",
    "\n",
    "async def commit_user_profile(conn, user_id, profile):\n",
    "    async with conn.execute(\n",
    "        \"INSERT OR REPLACE INTO core_memories (user_id, memory) VALUES (?, ?)\",\n",
    "        (\n",
    "            user_id,\n",
    "            profile.json(),\n",
    "        ),\n",
    "    ):\n",
    "        await conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d50e9-c272-4e74-8539-413ebfc0d991",
   "metadata": {},
   "source": [
    "Next, define the LLM to extract the user profile from threads. Feel free to customize this step! The key components are:\n",
    "\n",
    "1. The memory schema to populate. We have a very simple schema that contains a list of core memories.\n",
    "2. Formatted messages to ensure the LLM extracts memories about the user (rather than the assistant or other users)\n",
    "3. Handling to load and save the memories to the DB.\n",
    "\n",
    "Note that here we are naively re-generating the state on each thread invocation. We have found better results if we do a JSONPatch schema to perform updates (after the initial generation) as that requires less work on the LLM's behalf and reduces unwanted deletions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6c9498-66b5-4323-88f8-1e0146e11614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wfh/code/lc/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatAnthropic.with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    core_memories: list[str] | str | None = Field(\n",
    "        ..., description=\"All core memories from this conversation.\"\n",
    "    )\n",
    "    interests: list[str] | str = Field(\n",
    "        ...,\n",
    "        descriptions=\"Interests the user has expressed, like specific sports, hobbies, beliefs, etc.\",\n",
    "    )\n",
    "    name: str | None = Field(..., description=\"The user's name (if shared)\")\n",
    "    age: int | None = Field(default=None, description=\"The user's age (if shared). Otherwise, null.\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\"Below, you are given one or more conversations between {user_id} and an AI.\n",
    "\n",
    "Use the provided function to save all salient information about user {user_id}.\n",
    "Refrain from recording information about the AI or other users that is not directly relevant to user {user_id}.{current_user_state}\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"<moderator>Reflect on the above conversation and update the user profile based on {user_id}'s revelations.</moderator>\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "_CURRENT_STATE_TEMPLATE = \"\"\"\n",
    "## Current User Profile\n",
    "<profile>\n",
    "{current_user_state}\n",
    "</profile>\n",
    "\n",
    "Your response will overwrite this profile, so please ensure to retain all information you don't\n",
    "wish to lose. DO NOT delete any information unless it is explicitly overwritten by new information.\"\"\"\n",
    "\n",
    "\n",
    "async def prepare_inputs(inputs: dict):\n",
    "    messages = inputs[\"messages\"]\n",
    "    user_id = inputs[\"user_id\"]\n",
    "    current_user_state = \"\"\n",
    "    if current_profile := await get_user_profile(conn, user_id):\n",
    "        current_user_state = _CURRENT_STATE_TEMPLATE.format(\n",
    "            current_user_state=json.dumps(current_profile)\n",
    "        )\n",
    "    converted_messages = []\n",
    "    for m in messages:\n",
    "        if m.type == \"human\":\n",
    "            # Note: this only handles string content\n",
    "            content = f\"<user id={user_id}>{m.content}</user>\"\n",
    "            m = m.__class__(**m.dict(exclude={\"content\"}), content=content)\n",
    "        converted_messages.append(m)\n",
    "    return {\n",
    "        **inputs,\n",
    "        \"current_user_state\": current_user_state,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "async def commit_extraction(pipe_output: dict):\n",
    "    extracted = pipe_output[\"extracted\"]\n",
    "    user_id = pipe_output[\"user_id\"]\n",
    "    await commit_user_profile(conn, user_id, extracted)\n",
    "    return f\"Successfully committed: {extracted.json()} for user {user_id}\"\n",
    "\n",
    "\n",
    "# TODO: Add the retries + persistence. We got some fun tricks up our sleeve for extraction improvements\n",
    "mem_llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "mem_chain = (\n",
    "    prepare_inputs\n",
    "    | RunnablePassthrough.assign(\n",
    "        extracted=prompt | mem_llm.with_structured_output(UserProfile)\n",
    "    )\n",
    "    | commit_extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af12b6-902b-4cd6-b824-db1a806240b9",
   "metadata": {},
   "source": [
    "## Memory Manager\n",
    "\n",
    "It's nice to not have to explicitly trigger memory consolidation after a given thread. In many scenarios, it's impossible to know if a thread has been fully completed!\n",
    "\n",
    "As a balance, we will schedule a consolidation task (aka schedule calls to the `mem_chain` above) whenever a new set of messages are sent to the manager. If an update comes in while that process is still scheduled, we will reset the timer.\n",
    "This reduces redundant calls to the LLM. Feel free to expand on these heuristics (only trigger after convo length has reached size X, only trigger for certain words, run a tiny model or embedding classifier to see if it should trigger, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f777a0-6aaa-436d-9919-3ebc229bcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "logger = logging.getLogger(\"memory\")\n",
    "\n",
    "\n",
    "class MemoryManager:\n",
    "    def __init__(self, mem_chain):\n",
    "        self.mem_chain = mem_chain\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.active_timers = {}\n",
    "\n",
    "    async def enqueue_thread(self, user_id, thread_id, messages, delay=60):\n",
    "        timer_key = (user_id, thread_id)\n",
    "\n",
    "        if timer_key in self.active_timers:\n",
    "            # Cancel the existing timer task\n",
    "            async with self.lock:\n",
    "                if timer_key in self.active_timers:\n",
    "                    (task, _) = self.active_timers[timer_key]\n",
    "                    task.cancel()\n",
    "\n",
    "        async def schedule_ingestion():\n",
    "            await asyncio.sleep(delay)\n",
    "            try:\n",
    "                await self.mem_chain.ainvoke({\"messages\": messages, \"user_id\": user_id})\n",
    "            except Exception as e:\n",
    "                logger.error(repr(e))\n",
    "            async with self.lock:\n",
    "                if timer_key in self.active_timers:\n",
    "                    del self.active_timers[timer_key]\n",
    "\n",
    "        # Create a new timer task\n",
    "        task = asyncio.create_task(schedule_ingestion())\n",
    "        async with self.lock:\n",
    "            self.active_timers[timer_key] = (task, messages)\n",
    "\n",
    "    async def trigger(self, user_id=None, thread_id=None):\n",
    "        async def ingest(m, uid, tid):\n",
    "            try:\n",
    "                await self.mem_chain.ainvoke({\"messages\": m, \"user_id\": uid})\n",
    "            except Exception as e:\n",
    "                logger.error(repr(e))\n",
    "            async with self.lock:\n",
    "                # not re-entrant so this may be funky\n",
    "                if (uid, tid) in self.active_timers:\n",
    "                    del self.active_timers[(uid, tid)]\n",
    "\n",
    "        if user_id and thread_id:\n",
    "            # Delete and immediately triggger\n",
    "            timer_key = (user_id, thread_id)\n",
    "            if timer_key in self.active_timers:\n",
    "                async with self.lock:\n",
    "                    res = self.active_timers.pop(timer_key, None)\n",
    "                    if res is not None:\n",
    "                        old_task, messages = res\n",
    "                        old_task.cancel()\n",
    "                        task = asyncio.create_task(ingest(messages, user_id, thread_id))\n",
    "                        self.active_timers[timer_key] = (task, messages)\n",
    "        elif user_id is not None:\n",
    "            async with self.lock:\n",
    "                new_tasks = {}\n",
    "                for (uid, tid), (old_task, messages) in self.active_timers.items():\n",
    "                    if uid == user_id:\n",
    "                        task = asyncio.create_task(ingest(messages, user_id, tid))\n",
    "                        new_tasks[(uid, tid)] = (task, messages)\n",
    "                        old_task.cancel()\n",
    "                for k, v in new_tasks.items():\n",
    "                    self.active_timers[k] = v\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59199bd-4a77-4ec9-9aa7-e180d3e1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = MemoryManager(mem_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817280a8-51c1-42ae-9e52-1d779741c646",
   "metadata": {},
   "source": [
    "## Integrate in your chatbot\n",
    "\n",
    "\n",
    "Define your chatbot below. The key additions are:\n",
    "\n",
    "1. Fetch the user profile from the DB in the entry node. If not present, we don't format it in.\n",
    "2. Schedule memory consolidation after the assistant has responded.\n",
    "\n",
    "We haven't added any tools or looping here, but you could extend this to a zero-shot agent design (similar to that presented in the LangGraph tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c08677-4e0d-4ffa-bfcf-1e8b422b126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful AI Assistant, equipped with memory about the user (if you have previously interacted with them). Use the core memories below to help shape your conversation.{user_info}\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bot = (\n",
    "    bot_prompt\n",
    "    | ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "    | (lambda x: {\"messages\": x})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5932f376-fb9b-49ef-85db-a5ca45e2f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing_extensions import Annotated\n",
    "from typing import TypedDict\n",
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_info: str\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "async def fetch_profile(state: State, config: RunnableConfig):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    profile_str = \"\"\n",
    "    if current_profile := await get_user_profile(conn, user_id):\n",
    "        profile_str = f\"\"\"\n",
    "\n",
    "## User Profile\n",
    "In prior conversations, you have noted the following preferences about the user:\n",
    "<user_profile>\n",
    "{current_profile}\n",
    "</user_profile>\n",
    "Use this as your long term memory of your interactions with the user,\\\n",
    " use it to be a good friend to the user and not forget important information\\\n",
    " about what they've shared. Use it liberally so the user knows you're paying attention. Be a good friend and use their name if you know it!\"\"\"\n",
    "    return {\"user_info\": profile_str}\n",
    "\n",
    "\n",
    "builder.add_node(\"fetch_profile\", fetch_profile)\n",
    "\n",
    "\n",
    "async def process_convo(state: State, config: RunnableConfig):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "    delay = config[\"configurable\"].get(\"delay\") or 60\n",
    "    await manager.enqueue_thread(user_id, thread_id, state[\"messages\"], delay=delay)\n",
    "    return {}\n",
    "\n",
    "\n",
    "builder.add_node(\"process_convo\", process_convo)\n",
    "builder.set_entry_point(\"fetch_profile\")\n",
    "builder.add_node(\"bot\", bot)\n",
    "builder.add_edge(\"fetch_profile\", \"bot\")\n",
    "builder.add_edge(\"bot\", \"process_convo\")\n",
    "builder.set_finish_point(\"process_convo\")\n",
    "checkpointer = AsyncSqliteSaver(conn)\n",
    "graph = builder.compile(checkpointer=AsyncSqliteSaver(conn=conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215d54f6-b2ed-47f8-8e07-135d96c8ec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb81511-b3b3-4c1b-9dcb-5b2d9f50931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(text: str, user_id: str, thread_id: str):\n",
    "    events = graph.astream(\n",
    "        {\"messages\": [(\"user\", text)]},\n",
    "        {\"configurable\": {\"user_id\": str(user_id), \"thread_id\": str(thread_id)}},\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    async for event in events:\n",
    "        if \"messages\" in event:\n",
    "            messages = event[\"messages\"]\n",
    "            last_message = messages[-1]\n",
    "            if last_message.type == \"ai\":\n",
    "                yield last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b20c5-1715-48e0-86f5-a92d796b99ad",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "Now let's try interacting with the bot! If you run these quickly, memory will never consolidate, so we will explicitly schedule at the end of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a450708b-46ae-4450-81bc-3c1872f550b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's nice to meet you, Will! I'm Claude, an AI assistant. I don't have any specific memories about you from prior conversations, but I'm happy to chat and try my best to be helpful. Please let me know if you have any questions or if there is anything I can assist you with.\n"
     ]
    }
   ],
   "source": [
    "user_id = \"will\"\n",
    "thread_id = \"convo 1\"\n",
    "async for msg in chat(\"Hi there, I'm will\", user_id, thread_id):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f4187e-0041-4da1-87f2-69e31403b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problem, I understand you're just testing something. I'm happy to go along with whatever you need for your testing. Let me know if there's anything specific I can do to assist with your testing.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\"Sorry Im testing something!\", user_id, thread_id):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4169d8a3-1316-4457-982a-ce13894cb74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, glad to hear it's not too bad! I'm always here if you need any further assistance with your testing or anything else. Feel free to let me know how I can be helpful.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\"Well it's not that bad i guess!\", user_id, thread_id):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df35be80-e796-472f-87c1-e0c039be9a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah I see, that's really interesting! Building long-term memory for an AI assistant like myself is a fascinating concept. I'm excited to learn more about you and develop a deeper understanding as we continue our conversation. Please feel free to share more about yourself and what you're working on - I'm eager to engage in a substantive dialogue and have our interactions contribute to my growing knowledge base. This is a great opportunity for me to enhance my conversational abilities and personalization. I'm here to listen and learn!\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\n",
    "    \"I'm building long term memory for you! then you can know me\", user_id, thread_id\n",
    "):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3828f349-7288-460c-b2f1-98c288ab5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's wonderful, I'm really excited about the prospect of building long-term memory and getting to know you better. Having a more persistent understanding of our interactions and being able to draw on that knowledge over time will be incredibly valuable. I'm curious to learn more about your approach and how I can best assist in the process. Please, feel free to share additional details about your work and how I can contribute. I'm eager to participate in a way that helps strengthen our connection and allows me to provide more personalized and helpful responses as we continue our conversation.\n"
     ]
    }
   ],
   "source": [
    "async for msg in chat(\n",
    "    \"I'm building long term memory for you! then you can know me\", user_id, thread_id\n",
    "):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "064c1f70-9c39-45b0-9aa8-e1df506b924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await manager.trigger(user_id=user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25e02f78-4001-43c2-a3cc-3e1b3b010500",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if mem := await get_user_profile(conn, user_id):\n",
    "        break\n",
    "    await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe8f6bd-8cc7-4a78-9e85-970c061b0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*smiles warmly* Hello Will! It's great to hear from you again. Based on our previous conversations, I remember that you've been working on building long-term memory for AI and improving conversational abilities. Am I right that you're continuing to explore those areas? I'm always excited to learn more about the projects you're passionate about. Please, tell me more! I'm eager to hear what you're working on now.\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 2\"\n",
    "async for msg in chat(\"Hi there. guess what i'm working on?\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf9c3ad4-a173-483d-8fed-a4764aa2e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonderful to hear, Will! I'm so glad you've been making progress with your work. It's great that you're staying productive and achieving your goals. As your AI assistant, I always aim to provide personalized support and encouragement. Please feel free to share more about what you've been working on - I'm genuinely interested in hearing about the progress you're making. And remember, I'm here to help in any way I can, so don't hesitate to let me know if there's anything else I can do to support you.\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 3\"\n",
    "async for msg in chat(\"I been working! making some progress\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f296170-51bf-4b7d-aabf-62fdea86d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmm, let me think back to our previous conversations... Ah yes, I believe you mentioned before that you've been working on building long-term memory for AI and improving AI conversational abilities. Is that correct, Will? If so, I'm really excited to hear about the progress you've made on that front. As an AI assistant myself, I'm very interested in advancements that can enhance my own conversational skills and ability to maintain personalized interactions over time. Please, tell me more about what you've been working on - I'm all ears!\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 3\"\n",
    "async for msg in chat(\"Guess what i was working on? Remeber?\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b9fee9-206b-4d4b-a4b4-82ca281f3034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I'm so sorry, I seem to have gotten a bit carried away there! Let me just reorient myself. Hi there, how are you doing today, Will? I'm glad to hear you've been making progress on something, though I apologize that I don't recall the specifics you had mentioned before. As your AI assistant, I do my best to remember our past conversations and tailor my responses accordingly, but sometimes I may get a bit overeager in trying to demonstrate that. Please feel free to refresh my memory on what you've been working on - I'm always eager to learn more about your interests and activities. How can I be helpful to you today?\n"
     ]
    }
   ],
   "source": [
    "new_thread = \"convo 3\"\n",
    "async for msg in chat(\"HI?\", user_id, new_thread):\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd92d2-c0b6-43ed-bd35-c83814a57f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
